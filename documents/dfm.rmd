---
title: "Rによる日本語のテキスト分析：dfmの作成・操作・分析"
author: "渡辺耕平 (K.Watanabe1@lse.ac.uk)"
date: "6 May 2017"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/Documents/IJTA/")
knitr::opts_chunk$set(collapse = FALSE)
```

# dfm
**dfm**（document-feature matrix）は、行が文書で列が語を表す行列である。調査データなどと比較して、テキストデータは変数の数が多くなるため、**dfm**を作成した後に、`dfm_select()`や`dfm_trim()`などを用いて語の頻度などに基づき、特長語の抽出を行うと、期待した分析結果が出ることが多い。

## 作成
```{r, message=FALSE}
require(quanteda) # パッケージの読み込み
```
```{r creation}
load('data/data_corpus_asahi_2016.RData')

# 文書行列を作成
toks <- tokens(data_corpus_asahi_2016, remove_punct = TRUE)
mx <- dfm(toks)
nfeature(mx)
topfeatures(mx)
```

## 操作
```{r manipulation}

# 一文字語を削除
mx <- dfm_select(mx, min_nchar = 2)

# ひらがなを削除
mx <- dfm_remove(mx, '^[ぁ-ん]+$', valuetype = 'regex')

# 低頻度語を削除
mx <- dfm_trim(mx, min_count = 5)
nfeature(mx)
topfeatures(mx, 100)
```

## 分析
**dfm**は文字の文書内での位置を保持しないためいわゆるbag-of-wordsによるアプローチで、Rの一般線形モデルや主成分分析などを適用できるが、**quanteda**は、文書に特化した分析機能（`teststat_*()`）を複数含んでいる。

### 相対頻度分析
`teststat_keyness()`は二つの文書のグループを比較し、頻度が特別に高い（もしくは低い）語を抽出する。
```{r analysis1}

# 社会面の特長語抽出
keys <- textstat_keyness(mx, docvars(mx, 'section') == '１社会' | docvars(mx, 'section') == '２社会')
head(keys, 20)

```


### 辞書分析
**dfm**上で辞書分析を行うために`dfm_lookup()`を利用できるが、`dfm()`の`dictionary`引数に辞書を渡すことで、すぐさま分析の結果を得られる。
```{r analysis2}

# 感情分析辞書（Higashiyama et al. 2008) の読み込み
dict <- dictionary(file = 'extra/higashiyama_sentiment.yml')

names(toks) <- docvars(toks, 'date') # 文書名を日にちにする
wordage <- rowSums(dfm_compress(dfm(toks))) # 日ごとの総文字数
```

```{r plot1, echo=TRUE, results='asis', fig.height=5, fig.width=7, dpi=100}
toks_trump <- as.tokens(kwic(toks, "トランプ"))
mx_trump <- dfm(toks_trump, dictionary = dict)
mx_trump <- dfm_compress(mx_trump) # 日ごとに集計
mx_trump <- dfm_select(mx_trump, documents = unique(names(toks)), valuetype = 'fixed', padding = TRUE) # 日付を補完
mx_trump <- mx_trump[order(docnames(mx_trump)),] # 日にちで並べ替え
plot((mx_trump[,'positive'] - mx_trump[,'negative']) / wordage, type = 'l')

```
```{r plot2, echo=TRUE, results='asis', fig.height=5, fig.width=7, dpi=100}
toks_clinton <- as.tokens(kwic(toks, "クリントン"))
mx_clinton <- dfm(toks_clinton, dictionary = dict)
mx_clinton <- dfm_compress(mx_clinton) # 日ごとに集計
mx_clinton <- dfm_select(mx_clinton, documents = unique(names(toks)), valuetype = 'fixed', padding = TRUE) # 日付を補完
mx_clinton <- mx_clinton[order(docnames(mx_clinton)),] # 日にちで並べ替え
plot((mx_clinton[,'positive'] - mx_clinton[,'negative']) / wordage , type = 'l')
```

#### グラフのカスタマイズ
```{r plot3, echo=TRUE, results='asis', fig.height=5, fig.width=7, dpi=100}
plot((mx_trump[,'positive'] - mx_trump[,'negative']) / wordage, type = 'l', 
     xaxt = 'n', ylab = 'ポジティブ・ネガティブ比', xlab = '時間')
lines((mx_clinton[,'positive'] - mx_clinton[,'negative']) / wordage, col = 'red')
axis(1, at = 1:366, seq.Date(as.Date('2016-01-01'), as.Date('2016-12-31'), 'days'))
grid()
legend('topleft', col = c('black', 'red'), legend = c('トランプ', 'クリントン'), lty = 1)

```

### トピックモデル
トピックモデルは広く使われている教師なし文書分類手法の総称。トピックモデルを用いる場合は、**dfm**を`convert()`を通じて**topicmodels**や**LDA**など専門パッケージの文書行列オブジェクトへと変換する。なお、**topicmodels**をLinuxで利用するためには、コンソールで`sudo apt-get install libgsl0-dev1`を実行し、依存ファイルをインストールする必要がある。

```{r analysis3, cache=TRUE}
require(topicmodels)

mx_front <- mx[which(docvars(mx, 'page') == 1),]
lda_k20 <- LDA(convert(mx_front, to = "topicmodels"), k = 20) # 20のトピックを発見する
get_terms(lda_k20, 10) # 最も重要な10語を表示
```



