---
title: "Rによる日本語のテキスト分析：dfmの作成・操作・分析"
author: "渡辺耕平 (K.Watanabe1@lse.ac.uk)"
date: "6 May 2017"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/Documents/IJTA/")
knitr::opts_chunk$set(collapse = FALSE)
```

# dfm
**dfm**（document-feature matrix）は、行が文書で列が語を表す行列である。調査データなどと比較して、テキストデータは変数の数が多くなるため、**dfm**を作成した後に`dfm_select()`や`dfm_trim()`などを用いて、語の長さや頻度に基づいた特長語の選択を行うと、期待した分析結果を得られることが多い。

## 作成
```{r, message=FALSE}
require(quanteda) # パッケージの読み込み
```
```{r creation}
load('data/data_corpus_asahi_2016.rda')

# 文書行列を作成
toks <- tokens(data_corpus_asahi_2016, remove_punct = TRUE)
mx <- dfm(toks)
nfeature(mx)
topfeatures(mx)
```

## 操作
```{r manipulation}

# 一文字語を削除
mx <- dfm_select(mx, min_nchar = 2)

# ひらがなを削除
mx <- dfm_remove(mx, '^[ぁ-ん]+$', valuetype = 'regex')

# 低頻度語を削除
mx <- dfm_trim(mx, min_count = 5)
nfeature(mx)
topfeatures(mx, 100)
```

## 分析
**dfm**は文字の文書内での位置を保持しないためいわゆるbag-of-wordsによるアプローチで、Rの一般線形モデルや主成分分析などを適用できるが、**quanteda**は、文書に特化した分析機能（`teststat_*()`）を複数含んでいる。

### 相対頻度分析
`teststat_keyness()`は二つの文書のグループを比較し、頻度が特別に高い（もしくは低い）語を抽出する。
```{r analysis1}

# 社会面の特徴語抽出
keys <- textstat_keyness(mx, docvars(mx, 'section') == '１社会' | docvars(mx, 'section') == '２社会')
head(keys, 20)

```

### 辞書分析
基本的な手順では**dfm**上で辞書分析を行うために**dfm**を作成してから`dfm_lookup()`を用いるが、`dfm()`の`dictionary`引数に辞書を渡すことで、直接辞書分析の結果を得ることができる。
```{r analysis2}

# 感情分析辞書（Higashiyama et al. 2008) の読み込み
dict <- dictionary(file = 'extra/higashiyama_sentiment.yml')

date <- seq(as.Date('2016-01-01'), as.Date('2016-12-31'), by = '1 day') # すべての日にちを生成
```

```{r plot1, echo=TRUE, results='asis', fig.height=5, fig.width=7, dpi=100}
toks_trump <- as.tokens(kwic(toks, "トランプ"))
mx_trump <- dfm(toks_trump)
mx_trump <- dfm_lookup(mx_trump, dictionary = dict, nomatch = 'none')
mx_trump <- dfm_group(mx_trump, factor(docvars(mx_trump, 'date'), levels = as.factor(date)), fill = TRUE) # 日ごとに集計
mx_trump <- mx_trump[order(docnames(mx_trump)),] # 日にちで並べ替え
plot((mx_trump[,'positive'] - mx_trump[,'negative']) / nfeature(mx_trump), type = 'l')

```
```{r plot2, echo=TRUE, results='asis', fig.height=5, fig.width=7, dpi=100}

toks_clinton <- as.tokens(kwic(toks, "クリントン"))
mx_clinton <- dfm(toks_clinton)
mx_clinton <- dfm_lookup(mx_clinton, dictionary = dict, nomatch = 'none')
mx_clinton <- dfm_group(mx_clinton, factor(docvars(mx_clinton, 'date'), levels = as.factor(date)), fill = TRUE) # 日ごとに集計
mx_clinton <- mx_clinton[order(docnames(mx_clinton)),] # 日にちで並べ替え
plot((mx_clinton[,'positive'] - mx_clinton[,'negative']) / nfeature(mx_clinton), type = 'l')
```

#### グラフのカスタマイズ
```{r plot3, echo=TRUE, results='asis', fig.height=5, fig.width=7, dpi=100}
plot((mx_trump[,'positive'] - mx_trump[,'negative']) / nfeature(mx_trump), type = 'l', 
     xaxt = 'n', ylab = 'ポジティブ・ネガティブ比', xlab = '時間', ylim = c(-5, 10))
lines((mx_clinton[,'positive'] - mx_clinton[,'negative']) / nfeature(mx_clinton), col = 'red')
axis(1, at = 1:366, seq.Date(as.Date('2016-01-01'), as.Date('2016-12-31'), 'days'))
grid()
legend('topleft', col = c('black', 'red'), legend = c('トランプ', 'クリントン'), lty = 1)

```


### トピックモデル
トピックモデルは広く使われている教師なし文書分類手法の総称。トピックモデルを用いる場合は、**dfm**を`convert()`を通じて**topicmodels**や**LDA**などの専門パッケージ用の文書行列オブジェクトへと変換する。

なお、**topicmodels**をLinuxで利用するためには、コンソールで`sudo apt-get install libgsl0-dev1`を実行し、依存ファイルをインストールする必要がある。

```{r analysis3, cache=TRUE}
require(topicmodels)

mx_front <- mx[which(docvars(mx, 'page') == 1),]
lda_k20 <- LDA(convert(mx_front, to = "topicmodels"), k = 20) # 20のトピックを発見する
get_terms(lda_k20, 10) # 最も重要な10語を表示
```



